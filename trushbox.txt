    

    #tensor_plot2image(real_a,'realA_0',iteration)
    #tensor_plot2image(real_b,'realB_0',iteration)
    #tensor_plot2image(fake_b_hallsize,'fakeB_0',iteration)
    #vutils.save_image(real_a[0][0].detach(), '{}\\real_sample00_{:03d}.png'.format(os.getcwd() + '\\testing_output', epoch,normalize=True, nrow=8))
     
  
    #fake_b = real_a
#fakebの穴以外の箇所をrealaで上書きする
    center = math.floor(image_size / 2)
    d = math.floor(Local_Window / 4) #2→4(窓サイズの1/4)

    fake_b = real_b.clone() #参照渡しになっていたものを値渡しに変更
    #fake_b[:,:,center - d:center+d,center - d:center+d] = copy(fake_b_hallsize)

    #fake_b = fake_b_hallsize

    ############################
    # (1) Update D network: maximize log(D(x,y)) + log(1 - D(x,G(x)))
    # ペアで学習しているので　本物vsDiscriminator 偽物 vs Discriminator で執り行うのはどっちも同じ
    ###########################
    optimizerD_Global.zero_grad()
    optimizerD_Local.zero_grad()
    optimizerD_Edge.zero_grad()
    # train with fake

    #realAとFakebの穴周辺を切り出したものを用意する
    center = math.floor(image_size / 2)
    d = math.floor(Local_Window / 2) #trim(LocalDiscriminator用の窓)
    d2 = math.floor(Local_Window / 4) #L1Loss用の純粋な生成画像と同じサイズの窓用,所謂Mc

    real_a_trim = copy(real_a[:,:,center-d:center+d,center-d:center+d]) 
    real_b_trim = copy(real_b[:,:,center-d:center+d,center-d:center+d]) 
    fake_b_trim = copy(fake_b[:,:,center-d:center+d,center-d:center+d])

    real_a_trim2 = copy(real_a[:,:,center-d2:center+d2,center-d2:center+d2]) 
    real_b_trim2 = copy(real_b[:,:,center-d2:center+d2,center-d2:center+d2]) 
    fake_b_trim2 = copy(fake_b[:,:,center-d2:center+d2,center-d2:center+d2])


    fake_ab = torch.cat((real_b, fake_b), 1)
    fake_ab_trim = torch.cat((real_b_trim, fake_b_trim), 1)


    #tensor_plot2image(real_a,'realA_1',iteration)
    #tensor_plot2image(real_b,'realB_1',iteration)
    #tensor_plot2image(fake_b,'fakeB_1',iteration)

    #tensor_plot2image(real_a_trim,'realA_2',iteration)
    #tensor_plot2image(real_b_trim,'realB_2',iteration)
    #tensor_plot2image(fake_b_trim,'fakeB_2',iteration)
    #tensorを画像として扱うor .. トリミングする (後者を選択?)

    #reala,fakebのエッジ抽出
    #real_a_trim_8bit = (real_a_trim/256).astype('unit8') 

    #real_a_canny = cv2.Canny(real_a_trim, 100,600)
    #fake_b_canny = cv2.Canny(fake_b_trim, 100,600)
    #canny_ab = torch.cat((real_a_canny,fake_b_canny), 1)

    detatched_trim = fake_ab_trim.detach()
    detatched = fake_ab.detach()#detatched.shape ..[batchsize,6,256,256]
    #detatched_canny = canny_ab.detach()
    #グローバルDiscriminator


    #pred_fakeG = netD_Global.forward(fake_ab.detach()) #pred_dakeが偽画像を一時保存している
    #loss_d_fakeG = criterionGAN(pred_fakeG, False) #奥の引数はペアにした者が本か偽かを示すラベル

    #ローカルDiscriminator
    #pred_fakeL = netD_Local.forward(fake_ab_trim.detach()) #pred_dakeが偽画像を一時保存している
    #loss_d_fakeL = criterionGAN(pred_fakeL, False)

    #エッジDiscriminator(途中まで)
    #pred_fakeE = netD_Edge.forward(detatched_canny) #pred_dakeが偽画像を一時保存している
    #loss_d_fakeE = criterionGAN(pred_fakeE, False)

    # train with real
    #real_ab = torch.cat((real_b, real_b), 1) #torch.catはテンソルの連結splitの逆
    #real_ab_trim = torch.cat((real_b_trim, real_b_trim), 1)
    
    #pred_realG = netD_Global.forward(real_ab.detach())
    #loss_d_realG = criterionGAN(pred_realG, True)
    #pred_realL = netD_Local.forward(real_ab_trim.detach())
    #loss_d_realL = criterionGAN(pred_realL, True)
    #pred_realE = netD_Edge.forward(real_ab)
    #loss_d_realE = criterionGAN(pred_realE, True)
    # Combined loss
    #loss_d_fake = (loss_d_fakeG + loss_d_fakeL + loss_d_fakeE ) / 3 
    #loss_d_real = (loss_d_realG + loss_d_realL + loss_d_realE ) / 3 
    #loss_d_fake = (loss_d_fakeG + loss_d_fakeL) / 2
    #loss_d_real = (loss_d_realG + loss_d_realL) / 2 

    #loss_d = loss_d_fake + loss_d_real
    #loss_d.backward(retain_graph=True)
    #optimizerD_Global.step()
    #optimizerD_Local.step()
    #optimizerD_Edge.step()

    ############################
    # (2) Update G network: maximize log(D(x,G(x))) + L1(y,G(x))
    ##########################
   # optimizerG.zero_grad()
    # First, G(A) should fake the discriminator
    #fake_ab = torch.cat((real_a, fake_b), 1)
    #real_ab = torch.cat((real_b,real_b), 1)

    


   # pred_fakeG = netD_Global.forward(fake_ab.detach()) 
   # pred_fakeL = netD_Local.forward(fake_ab_trim.detach()) 
 
   # true_tensor = false_tensor = torch.clone(pred_fakeG)
   # true_tensor[:][:][:][:] = 1  #現状すべて0になっている
   # false_tensor[:][:][:][:] = 0


   # loss_g1 = criterionMSE(pred_fakeG, true_tensor)
   # loss_g2 = criterionMSE(pred_fakeL, true_tensor) #lossを統一することによってGeneratorが正しく機能するか？
